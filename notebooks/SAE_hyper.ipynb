{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ray[tune]\n",
      "  Downloading ray-2.39.0-cp310-cp310-manylinux2014_x86_64.whl (66.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./venvllm/lib/python3.10/site-packages (from pytorch-lightning) (24.1)\n",
      "Collecting lightning-utilities>=0.10.0\n",
      "  Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./venvllm/lib/python3.10/site-packages (from pytorch-lightning) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./venvllm/lib/python3.10/site-packages (from pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in ./venvllm/lib/python3.10/site-packages (from pytorch-lightning) (4.66.5)\n",
      "Requirement already satisfied: fsspec[http]>=2022.5.0 in ./venvllm/lib/python3.10/site-packages (from pytorch-lightning) (2024.2.0)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch>=2.1.0\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jsonschema\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Requirement already satisfied: filelock in ./venvllm/lib/python3.10/site-packages (from ray[tune]) (3.13.1)\n",
      "Requirement already satisfied: aiosignal in ./venvllm/lib/python3.10/site-packages (from ray[tune]) (1.3.1)\n",
      "Requirement already satisfied: requests in ./venvllm/lib/python3.10/site-packages (from ray[tune]) (2.32.3)\n",
      "Requirement already satisfied: frozenlist in ./venvllm/lib/python3.10/site-packages (from ray[tune]) (1.5.0)\n",
      "Requirement already satisfied: click>=7.0 in ./venvllm/lib/python3.10/site-packages (from ray[tune]) (8.1.7)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in ./venvllm/lib/python3.10/site-packages (from ray[tune]) (4.25.5)\n",
      "Collecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in ./venvllm/lib/python3.10/site-packages (from ray[tune]) (1.5.3)\n",
      "Collecting tensorboardX>=1.9\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in ./venvllm/lib/python3.10/site-packages (from ray[tune]) (18.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./venvllm/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.10.10)\n",
      "Requirement already satisfied: setuptools in ./venvllm/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (59.6.0)\n",
      "Requirement already satisfied: numpy in ./venvllm/lib/python3.10/site-packages (from tensorboardX>=1.9->ray[tune]) (1.26.3)\n",
      "Requirement already satisfied: networkx in ./venvllm/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.2.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./venvllm/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Requirement already satisfied: triton==3.1.0 in ./venvllm/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.0)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./venvllm/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./venvllm/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (9.1.0.70)\n",
      "Requirement already satisfied: jinja2 in ./venvllm/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.3)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venvllm/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Using cached rpds_py-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (360 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./venvllm/lib/python3.10/site-packages (from jsonschema->ray[tune]) (24.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venvllm/lib/python3.10/site-packages (from pandas->ray[tune]) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./venvllm/lib/python3.10/site-packages (from pandas->ray[tune]) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venvllm/lib/python3.10/site-packages (from requests->ray[tune]) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venvllm/lib/python3.10/site-packages (from requests->ray[tune]) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venvllm/lib/python3.10/site-packages (from requests->ray[tune]) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venvllm/lib/python3.10/site-packages (from requests->ray[tune]) (3.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venvllm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venvllm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./venvllm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venvllm/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in ./venvllm/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->ray[tune]) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venvllm/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.5)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venvllm/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.0)\n",
      "Installing collected packages: tensorboardX, rpds-py, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgpack, lightning-utilities, referencing, nvidia-cusparse-cu12, nvidia-cusolver-cu12, jsonschema-specifications, torch, jsonschema, torchmetrics, ray, pytorch-lightning\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformer-lens 0.0.0 requires torch<2.0,>=1.10, but you have torch 2.5.1 which is incompatible.\n",
      "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\n",
      "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\n",
      "algebraic-value-editing 0.2.0 requires torch==1.13.1, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jsonschema-4.23.0 jsonschema-specifications-2024.10.1 lightning-utilities-0.11.9 msgpack-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pytorch-lightning-2.4.0 ray-2.39.0 referencing-0.35.1 rpds-py-0.21.0 tensorboardX-2.6.2.2 torch-2.5.1 torchmetrics-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning ray[tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, EarlyStopping\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCheckpointCallback\n",
    "from ray import train, tune\n",
    "from ray.tune import Tuner, with_resources\n",
    "# from ray_lightning.tune import TuneReportCallback\n",
    "from ray.train import RunConfig\n",
    "\n",
    "# Set global parameters\n",
    "scale_factor = 11.888623072966611\n",
    "input_dim = 3072\n",
    "data_dir = os.path.join(os.getcwd(), \"activations_data\")\n",
    "# sample_rate = 0.1 # 10% of data\n",
    "sample_size = 8192 # file_size * sample_rate\n",
    "num_epochs = 1  # Only one epoch over all data\n",
    "\n",
    "# Dataset with Subsampling\n",
    "class ActivationDataset(Dataset):\n",
    "    def __init__(self, data_dir, f_type, test_fraction=0.01, scale_factor=1.0, batch_size=2048, seed=42):\n",
    "        self.data_dir = data_dir\n",
    "        self.test_fraction = test_fraction\n",
    "        self.scale_factor = scale_factor\n",
    "        self.batch_size = batch_size\n",
    "        self.multi = sample_size // batch_size\n",
    "        self.seed = seed\n",
    "        self.file_names = sorted([f for f in os.listdir(data_dir) if f.endswith('.npy') and f.startswith('activations_batch')])\n",
    "        if f_type not in [\"train\", \"test\"]:\n",
    "            raise ValueError(\"f_type must be 'train' or 'test'\")\n",
    "        if f_type == \"train\":\n",
    "            self.file_names = self.file_names[:int(len(self.file_names)*(1 - self.test_fraction))]\n",
    "        else:\n",
    "            self.file_names = self.file_names[int(len(self.file_names)*(1 - self.test_fraction)):]\n",
    "        self.f_type = f_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)*self.multi\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load a single file\n",
    "        f_ix = idx // self.multi # sample the file 4 times\n",
    "        file_path = os.path.join(self.data_dir, self.file_names[f_ix])\n",
    "        activations = np.load(file_path)[:, :-3]  # Remove metadata columns\n",
    "\n",
    "        # Normalize\n",
    "        activations = activations / self.scale_factor\n",
    "\n",
    "        # Random subsampling to sample_size\n",
    "        np.random.seed(self.seed + idx)  # Change seed per file for reproducibility\n",
    "        subsample_indices = np.random.choice(activations.shape[0], sample_size, replace=False)\n",
    "        activations = activations[subsample_indices]\n",
    "\n",
    "        # Get batch \n",
    "        batch_i = idx % self.multi\n",
    "        start = batch_i*self.batch_size\n",
    "        end = (batch_i+1)*self.batch_size\n",
    "        activations = activations[start:end]\n",
    "\n",
    "        # Convert to tensor\n",
    "        return torch.tensor(activations, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "# Model Definition\n",
    "class SparseAutoencoder(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, l1_lambda, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.l1_lambda = l1_lambda\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = torch.relu(self.encoder(x))\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded\n",
    "\n",
    "    def compute_loss(self, batch, decoded, encoded):\n",
    "        mse_loss = self.criterion(decoded, batch)\n",
    "        decoder_weight_norms = torch.norm(self.decoder.weight, p=2, dim=0)\n",
    "        l1_terms = encoded * decoder_weight_norms.unsqueeze(0)\n",
    "        l1_loss = torch.mean(torch.sum(l1_terms, dim=1))\n",
    "        return mse_loss, l1_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        decoded, encoded = self(batch)\n",
    "        mse_loss, l1_loss = self.compute_loss(batch, decoded, encoded)\n",
    "        total_loss = mse_loss + self.l1_lambda * l1_loss\n",
    "\n",
    "        # Compute active features\n",
    "        active_features = (encoded > 0).any(dim=0).float().mean().item() * 100\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"train_loss\", total_loss, on_step=True, on_epoch=True)\n",
    "        self.log(\"train_mse_loss\", mse_loss, on_step=True, on_epoch=True)\n",
    "        self.log(\"train_l1_loss\", l1_loss, on_step=True, on_epoch=True)\n",
    "        self.log(\"active_features\", active_features, on_step=True, on_epoch=True)\n",
    "        self.log(\"val_loss\", 0, on_step=True, on_epoch=True)\n",
    "        # train.report({\"loss\": total_loss, \"active_features\": active_features})\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        decoded, encoded = self(batch)\n",
    "        mse_loss, l1_loss = self.compute_loss(batch, decoded, encoded)\n",
    "        total_loss = mse_loss + self.l1_lambda * l1_loss\n",
    "\n",
    "        # Compute active features\n",
    "        active_features = (encoded > 0).any(dim=0).float().mean().item() * 100\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"val_loss\", total_loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_mse_loss\", mse_loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_l1_loss\", l1_loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_active_features\", active_features, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "# DataLoader Creation\n",
    "def create_data_loaders(batch_size):\n",
    "    train_dataset = ActivationDataset(data_dir, \"train\", 0.01, scale_factor, batch_size, 42)\n",
    "    val_dataset = ActivationDataset(data_dir, \"test\", 0.01, scale_factor, batch_size, 42)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)#, num_workers=3, pin_memory=True, persistent_workers=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Training Function with Ray Tune\n",
    "def train_model(config):\n",
    "    train_loader, val_loader = create_data_loaders(config[\"HB\"][\"batch_size\"])\n",
    "    model = SparseAutoencoder(input_dim, hidden_dim=config[\"HB\"][\"hidden_dim\"], l1_lambda=config[\"l1_lambda\"], lr=config[\"lr\"])\n",
    "\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"SparseAutoencoder\")\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=num_epochs,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        logger=logger,\n",
    "        # val_check_interval=0.25,  # Check validation 4 times per epoch\n",
    "        # max_time=\"00:30:00\",  # Stop after 30 minutes\n",
    "        enable_progress_bar=True, # Show progress bar\n",
    "        callbacks=[\n",
    "            LearningRateMonitor(logging_interval=\"step\"),\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\"),\n",
    "            TuneReportCheckpointCallback(\n",
    "                {\n",
    "                    \"train_loss\": \"train_loss\",\n",
    "                    \"train_mse_loss\": \"train_mse_loss\",\n",
    "                    \"train_l1_loss\": \"train_l1_loss\",\n",
    "                    \"active_features\": \"active_features\",\n",
    "                    \"val_loss\": \"val_loss\",\n",
    "                },\n",
    "                filename=\"none\",  # Do not save checkpoints\n",
    "                save_checkpoints = False,\n",
    "                on=\"train_batch_end\",\n",
    "            ),\n",
    "            TuneReportCheckpointCallback(\n",
    "                {\n",
    "                    \"val_loss\": \"val_loss\",\n",
    "                    \"val_mse_loss\": \"val_mse_loss\",\n",
    "                    \"val_l1_loss\": \"val_l1_loss\",\n",
    "                    \"val_active_features\": \"val_active_features\",\n",
    "                },\n",
    "                on=\"validation_end\",\n",
    "            ),\n",
    "            # RayTrainReportCallback(),\n",
    "        ],\n",
    "        # strategy=RayDDPStrategy(), # Use Ray for distributed training, DDP stands for Distributed Data Parallel\n",
    "        # callbacks=[RayTrainReportCallback()], # Report metrics to Ray\n",
    "        # plugins=[RayLightningEnvironment()], # Use Ray for distributed training\n",
    "    )\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Ray Tune Hyperparameter Search\n",
    "def tune_hyperparameters():\n",
    "\n",
    "    # possible_hidden_dims = [4096, 8192, 16384, 20000, 32768]\n",
    "    # possible_batch_sizes = [512, 1024, 2048, 4096, 8192]\n",
    "    possible_hidden_dims = [8192, 16384, 20000, 32768]\n",
    "    possible_batch_sizes = [1024, 2048, 4096]\n",
    "\n",
    "    valid_hb_pairs = []\n",
    "    for hidden_dim in possible_hidden_dims:\n",
    "        for batch_size in possible_batch_sizes:\n",
    "            if hidden_dim * batch_size <= 41_000_000: # VRAM limit\n",
    "                valid_hb_pairs.append({\"hidden_dim\": hidden_dim, \"batch_size\": batch_size})\n",
    "\n",
    "\n",
    "    # search_space = {\n",
    "    #     \"hidden_dim\": tune.choice([4096, 8192, 16384, 20000, 32768]),\n",
    "    #     \"batch_size\": tune.choice([512, 1024, 2048, 4096, 8192]),\n",
    "    #     \"l1_lambda\": tune.loguniform(1e-4, 1e-2),\n",
    "    #     \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "    # }\n",
    "\n",
    "    search_space = {\n",
    "        \"HB\": tune.choice(valid_hb_pairs),\n",
    "        \"l1_lambda\": tune.loguniform(1e-4, 1e-2),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "    }\n",
    "\n",
    "    # scheduler_asha = tune.schedulers.ASHAScheduler(\n",
    "    #     max_t=num_epochs,\n",
    "    #     grace_period=1,\n",
    "    #     reduction_factor=2,\n",
    "    # )\n",
    "\n",
    "    # os.environ[\"RAY_CHDIR_TO_TRIAL_DIR\"] = \"0\" # Allows relative paths, but trials are not isolated\n",
    "\n",
    "    trainable_with_resources = with_resources(\n",
    "        train_model,\n",
    "        {\"cpu\":4, \"gpu\": 1}  # Adjust based on your available resources\n",
    "    )\n",
    "\n",
    "    tuner = Tuner(\n",
    "        trainable=trainable_with_resources,\n",
    "        param_space=search_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            num_samples=1, # Number of hyperparameter sets to try\n",
    "            max_concurrent_trials=10, # Number of trials to run concurrently\n",
    "            # scheduler=scheduler_asha,\n",
    "        ),\n",
    "        run_config=RunConfig(\n",
    "            name=\"hyperparameter_search\",\n",
    "            storage_path=str(Path(\"./results\").resolve()),\n",
    "        ),\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(metric=\"val_loss\", mode=\"min\")\n",
    "    print(\"Best Hyperparameters Found:\")\n",
    "    print(best_result.config)\n",
    "    return results\n",
    "\n",
    "# # Run Hyperparameter Search\n",
    "# if __name__ == \"__main__\":\n",
    "#     tune_hyperparameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-11-29 01:43:46</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:13.72        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.4/15.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_f5826_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-29_01-43-30_676248_535939/artifacts/2024-11-29_01-43-32/hyperparameter_search/driver_artifacts/train_model_f5826_00000_0_HB=hidden_dim_20000_batch_size_2048,l1_lambda=0.0001,lr=0.0001_2024-11-29_01-43-32/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc                  </th><th>HB                  </th><th style=\"text-align: right;\">  l1_lambda</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_f5826_00000</td><td>ERROR   </td><td>192.168.178.90:537105</td><td>{&#x27;hidden_dim&#x27;: _8980</td><td style=\"text-align: right;\">0.000126523</td><td style=\"text-align: right;\">0.000103278</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=537105)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 2024-11-29 01:43:37.310373: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m E0000 00:00:1732841017.327900  537222 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m E0000 00:00:1732841017.333131  537222 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 2024-11-29 01:43:37.352424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_model pid=537105)\u001b[0m \n",
      "\u001b[36m(train_model pid=537105)\u001b[0m   | Name      | Type    | Params | Mode \n",
      "\u001b[36m(train_model pid=537105)\u001b[0m ----------------------------------------------\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 0 | encoder   | Linear  | 61.5 M | train\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 1 | decoder   | Linear  | 61.4 M | train\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 2 | criterion | MSELoss | 0      | train\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m ----------------------------------------------\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 122 M     Trainable params\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 122 M     Total params\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 491.612   Total estimated model params size (MB)\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 3         Modules in train mode\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m 0         Modules in eval mode\n",
      "\u001b[36m(train_model pid=537105)\u001b[0m /home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  4.69it/s]\n",
      "Epoch 0:   0%|          | 0/128 [00:00<?, ?it/s]                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 01:43:46,194\tERROR tune_controller.py:1331 -- Trial task failed for trial train_model_f5826_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=537105, ip=192.168.178.90, actor_id=6b8292fa039b0b2121209d8a01000000, repr=train_model)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/ray/air/_internal/util.py\", line 104, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_535939/848624529.py\", line 179, in train_model\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 212, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py\", line 133, in __next__\n",
      "    batch = super().__next__()\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/loops/fetchers.py\", line 60, in __next__\n",
      "    batch = next(self.iterator)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 78, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1465, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1491, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/torch/_utils.py\", line 715, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/tmp/ipykernel_535939/848624529.py\", line 66, in __getitem__\n",
      "  File \"/home/drew99/IJS/LLMinfluence/venvllm/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n",
      "2024-11-29 01:43:46,202\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/drew99/IJS/LLMinfluence/results/hyperparameter_search' in 0.0025s.\n",
      "2024-11-29 01:43:46,206\tERROR tune.py:1037 -- Trials did not complete: [train_model_f5826_00000]\n",
      "2024-11-29 01:43:46,207\tINFO tune.py:1041 -- Total run time: 13.75 seconds (13.72 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters Found:\n",
      "{'HB': {'hidden_dim': 20000, 'batch_size': 2048}, 'l1_lambda': 0.0001265234404620061, 'lr': 0.00010327792598627444}\n"
     ]
    }
   ],
   "source": [
    "results = tune_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Ray Tune experiments\n",
    "# ls ./ray_results\n",
    "\n",
    "# Show the best trial from an experiment\n",
    "# cat ./ray_results/<experiment_name>/best_result.json\n",
    "\n",
    "\n",
    "# tensorboard --logdir tb_logs\n",
    "# tensorboard --logdir=~/ray_results/my_experiment\n",
    "\n",
    "\n",
    "# ray dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-637220e34d1bf6b3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-637220e34d1bf6b3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./results/hyperparameter_search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
